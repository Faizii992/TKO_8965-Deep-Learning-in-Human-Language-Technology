{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Q_pocEP3btAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1ac530-99bc-426a-b22b-e0cda9aac9ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD90Y8gNbig5",
        "outputId": "81e9d5c7-b169-40d4-be51-a779aeb7496c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text  [{'generated_text': \"Once upon a time when most of us thought we had accomplished something, it took a long time to realize we haven't, if anything, accomplished the\"}, {'generated_text': \"Once upon a time when you'd thought of this as something far simpler, not less, the name itself was, but it wasn't. A brief\"}, {'generated_text': 'Once upon a time when our world was in a more or less deadly state, the whole world was looking for new forms of freedom. If the'}, {'generated_text': 'Once upon a time when it was known to be hard to tell who was right, it was revealed that the true and most holy was called and believed'}, {'generated_text': 'Once upon a time when the first and second place are two things; when it was understood that the one who had the advantage above it was above,'}, {'generated_text': 'Once upon a time when America has become the major power on the planet, the US is now being called the \"power in the world.\" Now,'}]\n",
            "Generated Sequence for GPT-2 1:\n",
            "Once upon a time when most of us thought we had accomplished something, it took a long time to realize we haven't, if anything, accomplished the\n",
            "\n",
            "Generated Sequence for GPT-2 2:\n",
            "Once upon a time when you'd thought of this as something far simpler, not less, the name itself was, but it wasn't. A brief\n",
            "\n",
            "Generated Sequence for GPT-2 3:\n",
            "Once upon a time when our world was in a more or less deadly state, the whole world was looking for new forms of freedom. If the\n",
            "\n",
            "Generated Sequence for GPT-2 4:\n",
            "Once upon a time when it was known to be hard to tell who was right, it was revealed that the true and most holy was called and believed\n",
            "\n",
            "Generated Sequence for GPT-2 5:\n",
            "Once upon a time when the first and second place are two things; when it was understood that the one who had the advantage above it was above,\n",
            "\n",
            "Generated Sequence for GPT-2 6:\n",
            "Once upon a time when America has become the major power on the planet, the US is now being called the \"power in the world.\" Now,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the text generation pipeline for GPT-2\n",
        "generator_GPT = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Generate text\n",
        "generated_text = generator_GPT(\"Once upon a time when\", max_length=30, num_return_sequences=6)\n",
        "print(\"Generated text \",generated_text)\n",
        "# Print generated text\n",
        "for i, sequence in enumerate(generated_text):\n",
        "    print(f\"Generated Sequence for GPT-2 {i + 1}:\")\n",
        "    print(sequence['generated_text'])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the text generation pipeline for GPT-2\n",
        "generator_GPT = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Generate text\n",
        "generated_text = generator_GPT(\"A long long time ago there happened to be\", max_length=30, num_return_sequences=4)\n",
        "print(\"Generated text \",generated_text)\n",
        "# Print generated text\n",
        "for i, sequence in enumerate(generated_text):\n",
        "    print(f\"Generated Sequence for GPT-2 {i + 1}:\")\n",
        "    print(sequence['generated_text'])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoCDz7qpyeVp",
        "outputId": "636f8edb-1c9c-4941-dfbe-687e3e8709b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text  [{'generated_text': 'A long long time ago there happened to be a fire that broke out in front of the hospital.\\n\\nA few hours later, I looked at'}, {'generated_text': \"A long long time ago there happened to be a new name for the species Homo sapiens, and what that name and the scientific name meant wasn't\"}, {'generated_text': \"A long long time ago there happened to be some good things. Sometimes they're nice and sometimes nice aren't. But they do come with the price\"}, {'generated_text': 'A long long time ago there happened to be what we would called a \"Birds\" (also known as The Boulders) nest on this'}]\n",
            "Generated Sequence for GPT-2 1:\n",
            "A long long time ago there happened to be a fire that broke out in front of the hospital.\n",
            "\n",
            "A few hours later, I looked at\n",
            "\n",
            "Generated Sequence for GPT-2 2:\n",
            "A long long time ago there happened to be a new name for the species Homo sapiens, and what that name and the scientific name meant wasn't\n",
            "\n",
            "Generated Sequence for GPT-2 3:\n",
            "A long long time ago there happened to be some good things. Sometimes they're nice and sometimes nice aren't. But they do come with the price\n",
            "\n",
            "Generated Sequence for GPT-2 4:\n",
            "A long long time ago there happened to be what we would called a \"Birds\" (also known as The Boulders) nest on this\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "FGRSvg2NyfFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Z2ErNS_xPBK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}